{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Machine learning approaches to Fake news Detection"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"fake = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")\ntrue = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data cleaning and preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding flags to recognize fake and real\nfake['target'] = 'fake'\ntrue['target'] = 'true'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding both the dataframes\ndata = pd.concat([fake, true]).reset_index(drop = True)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shuffling the data\nfrom sklearn.utils import shuffle\ndata = shuffle(data)\ndata = data.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viewing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing the dates and title from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"date\"],axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"title\"],axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting to lowercase for easy analysis\ndata['text'] = data['text'].apply(lambda x: x.lower())\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the punctuations\nimport string\n\ndef punctuation_removal(text):\n    all_list = [char for char in text if char not in string.punctuation]\n    clean_str = ''.join(all_list)\n    return clean_str\n\ndata['text'] = data['text'].apply(punctuation_removal)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Stopwards\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\ndata['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() \n                                                      if word not in (stop)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Articles per subject and it's bar plot\nprint(data.groupby(['subject'])['text'].count())\ndata.groupby(['subject'])['text'].count().plot(kind=\"bar\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of fake and real news articles\nprint(data.groupby(['target'])['text'].count())\ndata.groupby(['target'])['text'].count().plot(kind=\"bar\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making a word cloud for fake news\nfrom wordcloud import WordCloud\n\nfake_data = data[data[\"target\"] == \"fake\"]\nall_words = ' '.join([text for text in fake_data.text])\n\nwordcloud = WordCloud(width= 800, height= 500,\n                          max_font_size = 110,\n                          collocations = False).generate(all_words)\n\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making a word cloud for real news\nfrom wordcloud import WordCloud\n\nreal_data = data[data[\"target\"] == \"true\"]\nall_words = ' '.join([text for text in fake_data.text])\n\nwordcloud = WordCloud(width= 800, height= 500,\n                          max_font_size = 110,\n                          collocations = False).generate(all_words)\n\nplt.figure(figsize=(10,7))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Most frequent words counter\nfrom nltk import tokenize\n\ntoken_space = tokenize.WhitespaceTokenizer()\n\ndef counter(text, column_text, quantity):\n    all_words = ' '.join([text for text in text[column_text]])\n    token_phrase = token_space.tokenize(all_words)\n    frequency = nltk.FreqDist(token_phrase)\n    df_frequency = pd.DataFrame({\"Word\": list(frequency.keys()),\n                                   \"Frequency\": list(frequency.values())})\n    df_frequency = df_frequency.nlargest(columns = \"Frequency\", n = quantity)\n    plt.figure(figsize=(12,8))\n    ax = sns.barplot(data = df_frequency, x = \"Word\", y = \"Frequency\", color = 'blue')\n    ax.set(ylabel = \"Count\")\n    plt.xticks(rotation='vertical')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Most Frequent words in fake news\ncounter(data[data[\"target\"] == \"fake\"], \"text\", 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Most frequent words in real news\ncounter(data[data[\"target\"] == \"true\"], \"text\", 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling\nPlotting the confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data\nX_train,X_test,y_train,y_test = train_test_split(data['text'], data.target, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vectorizing and applying TF-IDF\nfrom sklearn.linear_model import LogisticRegression\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\n# Fitting the model\nmodel = pipe.fit(X_train, y_train)\n\n# Accuracy\nprediction = model.predict(X_test)\nprint(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = metrics.confusion_matrix(y_test, prediction)\nplot_confusion_matrix(cm, classes=['Fake', 'Real'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Vectorizing and applying TF-IDF\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n                                           max_depth = 20, \n                                           splitter='best', \n                                           random_state=42))])\n# Fitting the model\nmodel = pipe.fit(X_train, y_train)\n\n# Accuracy\nprediction = model.predict(X_test)\nprint(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = metrics.confusion_matrix(y_test, prediction)\nplot_confusion_matrix(cm, classes=['Fake', 'Real'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', RandomForestClassifier(n_estimators=50, criterion=\"entropy\"))])\n\nmodel = pipe.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = metrics.confusion_matrix(y_test, prediction)\nplot_confusion_matrix(cm, classes=['Fake', 'Real'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}